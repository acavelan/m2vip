Notes: 

- On test des matrices de taille 256, 512, 1024, 2048, 4096
- Pour N > 1024 le cache est trop petit et on observe de grosses différences

Machines:
- OrdiCentre Intel Celeron (x2)
- Asus Intel Core i7 (x4 + 4)

Benchs
================================================================================

naive                   - triple boucle ligne / colonnes
cache                   - ligne / ligne
cache-unroll-1-4
cache-unroll-1-8    
cache-unroll-1-16   
cache-unroll-2-4 
cache-unroll-2-8 
cache-unroll-2-16
cache-unroll-1-4-sse
cache-unroll-1-8-sse
cache-unroll-1-16-sse
cache-unroll-2-4-sse
cache-unroll-2-8-sse
cache-unroll-2-16-sse
cache-unroll-4-4-sse
cache-unroll-4-8-sse
blocks                  - optimisation du cache par blocs (bloc = taille du cache)

Recherche du bloc optimal pour la machine X
===========================================

blocks-unroll-1-4
blocks-unroll-1-8    
blocks-unroll-1-16   
blocks-unroll-2-4 
blocks-unroll-2-8 
blocks-unroll-2-16
blocks-unroll-1-4-sse
blocks-unroll-1-8-sse
blocks-unroll-1-16-sse
blocks-unroll-2-4-sse
blocks-unroll-2-8-sse
blocks-unroll-2-16-sse
blocks-unroll-4-4-sse
blocks-unroll-4-8-sse

=> Résultats dans stats/

Recherche des meilleurs implémentations et parallélisation
==========================================================

naïf-omp-2
naïf-omp-4
naïf-omp-8

cache-omp-2
cache-omp-4
cache-omp-8

blocks-omp-2
blocks-omp-4
blocks-omp-8


Experimentations
================================================================================

Hugepages
CUDA


Comparaisons
================================================================================

- CBLAS		7700, i7
- Eigen		890, i7
- Matlab
- Python
- Java
- D
